<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width">
    <meta name="google-site-verification" content="iplyfI0Y6pOe8NsNYwwrKe-QfSYamSeEhQiDFh93NiU">
    <title>Try Kubernetes with Vagrant - chris-rock
    </title>
    <link rel="alternate" href="http://lollyrock.com/feed.xml" type="application/rss+xml" title="fun &amp; sun">
    <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic|Anonymous+Pro:400,700,400italic,700italic|Merriweather:400,700,300">
    <link rel="stylesheet" href="/css/main.css">
    <script type="text/javascript">
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-50992958-1', 'lollyrock.com');
      ga('send', 'pageview');
    </script>
    <script type="text/javascript">
      !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');
      
    </script>
  </head>
  <body class="article-detail">
    <header class="header">
      <div class="content-wrap">
        <h1>Try Kubernetes with Vagrant</h1>
        <p class="author">Written by <span class="author"><a href="mailto:chris@lollyrock.com">Christoph Hartmann</a></span>
        </p>
      </div>
    </header>
    <div id="content">
      <div class="content-wrap">
        <article class="article">
          <section class="content"><p>To get familiar with kubernetes, it is always good to start with an example. This blog post will setup nginx running on&nbsp;kubernetes.</p>
<h2 id="prerequisites-aka-setup-the-cluster">Prerequisites aka setup the&nbsp;cluster</h2>
<p>Before we are able to start, we need to download kubernetes and install the command line. To prepare the&nbsp;setup:</p>
<ul>
<li>install <a href="http://www.vagrantup.com/downloads.html">Vagrant</a>&nbsp;(&gt;1.6.2)</li>
<li>install <a href="https://www.virtualbox.org/wiki/Downloads">VirtualBox</a></li>
</ul>
<p>Then clone the git repository and set the provider for kubernetes setup&nbsp;scripts </p>
<pre><code class="lang-bash">git <span class="built_in">clone</span> https://github.com/GoogleCloudPlatform/kubernetes.git
<span class="built_in">export</span> KUBERNETES_PROVIDER=vagrant
<span class="built_in">cd</span> kubernetes
</code></pre>
<p>Now, we are ready to start the Vagrant cluster. With <code>kube-up.sh</code> vagrant will provision each machine in the cluster. All necessary components to run kubernetes are installed automatically. By default, each <span class="caps">VM</span> is running Fedora as base&nbsp;OS.</p>
<pre><code class="lang-bash">$ ./cluster/kube-up.sh
Starting cluster using provider: vagrant
... calling verify-prereqs
... calling kube-up

...

Wrote config <span class="keyword">for</span> vagrant to /Users/chris/.kube/config
Each machine instance has been created/updated.
  Now waiting <span class="keyword">for</span> the Salt provisioning process to complete on each machine.
  This can take some time based on your network, disk, and cpu speed.
  It is possible <span class="keyword">for</span> an error to occur during Salt provision of cluster and this could loop forever.
Validating master
Validating minion-1
.....
Waiting <span class="keyword">for</span> each minion to be registered with cloud provider

...

Kubernetes cluster is running.  The master is running at:

  https://10.245.1.2

The user name and password to use is located <span class="keyword">in</span> ~/.kubernetes_vagrant_auth.

... calling validate-cluster
Found 1 nodes.
     1  <span class="caps">NAME</span>         LABELS    STATUS
     2  10.245.1.3   &lt;none&gt;    Ready
Validate output:
NAME                 STATUS    MESSAGE   ERROR
controller-manager   Healthy   ok        nil
scheduler            Healthy   ok        nil
etcd-0               Healthy   {<span class="string">"action"</span>:<span class="string">"get"</span>,<span class="string">"node"</span>:{<span class="string">"dir"</span>:<span class="literal">true</span>,<span class="string">"nodes"</span>:[{<span class="string">"key"</span>:<span class="string">"/registry"</span>,<span class="string">"dir"</span>:<span class="literal">true</span>,<span class="string">"modifiedIndex"</span>:3,<span class="string">"createdIndex"</span>:3}]}}
                     nil
Cluster validation succeeded
Done, listing cluster services:

Kubernetes master is running at https://10.245.1.2
kube-dns is running at https://10.245.1.2/api/v1beta3/proxy/namespaces/default/services/kube-dns
</code></pre>
<p>Verify that kubernetes is&nbsp;running:</p>
<pre><code class="lang-bash">$ curl --user vagrant:vagrant --insecure https://10.245.1.2/ 
{
  <span class="string">"paths"</span>: [
    <span class="string">"/api"</span>,
    <span class="string">"/api/v1beta1"</span>,
    <span class="string">"/api/v1beta2"</span>,
    <span class="string">"/api/v1beta3"</span>,
    <span class="string">"/healthz"</span>,
    <span class="string">"/healthz/ping"</span>,
    <span class="string">"/logs/"</span>,
    <span class="string">"/metrics"</span>,
    <span class="string">"/static/"</span>,
    <span class="string">"/swagger-ui/"</span>,
    <span class="string">"/swaggerapi/"</span>,
    <span class="string">"/validate"</span>,
    <span class="string">"/version"</span>
  ]
}
</code></pre>
<p>You could also be able to ssh into master and&nbsp;minion:</p>
<pre><code class="lang-bash">$ vagrant ssh master
$ vagrant ssh minion-1
</code></pre>
<p>Further details are available at <a href="https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/vagrant.md">Kubernetes Vagrant&nbsp;Documentation</a></p>
<h2 id="do-some-magic-with-kubernetes-cli">Do some magic with Kubernetes&nbsp;<span class="caps">CLI</span></h2>
<p>You could use the <code>cluster/kubectl.sh</code>, but I find it much easier to install the <code>kubectl</code> binary. This can be easily done&nbsp;via:</p>
<pre><code class="lang-bash"><span class="comment"># use mac binary</span>
$ wget https://storage.googleapis.com/kubernetes-release/release/v0.17.0/bin/darwin/amd64/kubectl -O /usr/<span class="built_in">local</span>/bin/kubectl
$ chmod +x /usr/<span class="built_in">local</span>/bin/kubectl
$ kubectl version
</code></pre>
<p>Now, we have the <code>kubectl</code> command ready for&nbsp;use.</p>
<h2 id="start-nginx-cluster-without-pod-definition">Start Nginx cluster without pod&nbsp;definition</h2>
<p>This first example uses the docker nginx image and runs it as a cluster. It uses a replica of 3 during bootstrap. Afterwards we change the replica to 2 containers. Finally we destroy all running&nbsp;containers.</p>
<pre><code class="lang-bash"><span class="comment"># Create new nginx cluster</span>
$ kubectl run-container webserver --image=nginx --replicas=3 --port=80
<span class="caps">CONTROLLER</span>   CONTAINER(S)   IMAGE(S)   SELECTOR                  REPLICAS
webserver    webserver      nginx      run-container=webserver   3

<span class="comment"># Show all running pods</span>
$ kubectl get pods -l run-container=webserver
<span class="caps">POD</span>               IP            CONTAINER(S)   IMAGE(S)   HOST                    LABELS                    STATUS    CREATED      MESSAGE
webserver-6de4a   10.246.1.17                             10.245.1.3/10.245.1.3   run-container=webserver   Running   27 seconds   
                                webserver      nginx                                                        Running   25 seconds   
webserver-koxmk   10.246.1.19                             10.245.1.3/10.245.1.3   run-container=webserver   Running   27 seconds   
                                webserver      nginx                                                        Running   24 seconds   
webserver-lt0e9   10.246.1.18                             10.245.1.3/10.245.1.3   run-container=webserver   Running   27 seconds   
                                webserver      nginx                                                        Running   24 seconds   

$ kubectl get replicationControllers -l run-container=webserver
CONTROLLER   CONTAINER(S)   IMAGE(S)   SELECTOR                  REPLICAS
webserver    webserver      nginx      run-container=webserver   3

<span class="comment"># Resize the replica:</span>
$ kubectl resize rc webserver --replicas=2
resized

$ kubectl get replicationControllers -l run-container=webserver
<span class="caps">CONTROLLER</span>   CONTAINER(S)   IMAGE(S)   SELECTOR                  REPLICAS
webserver    webserver      nginx      run-container=webserver   2

<span class="comment"># Show all kube nodes, previously `kubectl get minions`</span>
$ kubectl get nodes
<span class="caps">NAME</span>         LABELS    STATUS
10.245.1.3   &lt;none&gt;    Ready

<span class="comment"># Delete running nginx pod with all replicas and services</span>
$ kubectl stop pods,services -l run-container=webserver
$ kubectl delete pods,services -l run-container=webserver
$ kubectl resize rc webserver --replicas=2
pods/webserver-6de4a
pods/webserver-koxmk
</code></pre>
<h2 id="start-nginx-cluster-with-pods-definition">Start Nginx cluster with pods&nbsp;definition</h2>
<p>We define a pod definition <code>01-nginx.yaml</code> to get nginx up and running. The meta data describes the name and labels of the container. This is required to define selectors for replicas, as we use it later. The <code>containers</code> define the used docker image. Create the following&nbsp;file:</p>
<pre><code class="lang-yaml"><span class="comment"># 01-nginx.yaml</span>
<span class="attr">apiVersion:</span> <span class="string">v1beta3</span>
<span class="attr">kind:</span> <span class="string">Pod</span>
<span class="attr">metadata:</span>
<span class="attr">  name:</span> <span class="string">www</span>
<span class="attr">  labels:</span> 
<span class="attr">    name:</span> <span class="string">www-nginx</span>
<span class="attr">spec:</span>
<span class="attr">  containers:</span>
<span class="attr">    - name:</span> <span class="string">nginx</span>
<span class="attr">      image:</span> <span class="string">nginx</span>
<span class="attr">      ports:</span>
<span class="attr">        - containerPort:</span> <span class="number">80</span>
</code></pre>
<p>Load the pod into&nbsp;kubernetes.</p>
<pre><code class="lang-bash"><span class="comment"># Start nginx pod/container</span>
$ kubectl create -f 01-nginx.yaml 
pods/www

<span class="comment"># Check that nginx is running</span>
$ kubectl get pods -l name=www-nginx
</code></pre>
<p>Now, we adapt the replica by creating a new <code>ReplicationController</code> definition:</p>
<pre><code class="lang-yaml"><span class="comment"># 01-nginx-replica.yaml</span>
<span class="attr">apiVersion:</span> <span class="string">v1beta3</span>
<span class="attr">kind:</span> <span class="string">ReplicationController</span>
<span class="attr">metadata:</span>
<span class="attr">  name:</span> <span class="string">nginx-controller</span>
<span class="attr">spec:</span>
<span class="attr">  replicas:</span> <span class="number">2</span>
  <span class="comment"># selector identifies the set of Pods that this</span>
  <span class="comment"># replication controller is responsible for managing</span>
<span class="attr">  selector:</span>
<span class="attr">    name:</span> <span class="string">www-nginx</span>
  <span class="comment"># podTemplate defines the 'cookie cutter' used for creating</span>
  <span class="comment"># new pods when necessary</span>
<span class="attr">  template:</span>
<span class="attr">    metadata:</span>
<span class="attr">      name:</span> <span class="string">www</span>
<span class="attr">      labels:</span>
        <span class="comment"># Important: these labels need to match the selector above</span>
        <span class="comment"># The api server enforces this constraint.</span>
<span class="attr">        name:</span> <span class="string">www-nginx</span>
<span class="attr">    spec:</span>
<span class="attr">      containers:</span>
<span class="attr">        - name:</span> <span class="string">nginx</span>
<span class="attr">          image:</span> <span class="string">nginx</span>
<span class="attr">          ports:</span>
<span class="attr">            - containerPort:</span> <span class="number">80</span>
</code></pre>
<p>Load the new definition into&nbsp;kubernetes:</p>
<pre><code class="lang-bash"><span class="comment"># Increase replica of the current nginx instances</span>
$ kubectl create -f 01-nginx-replica.yaml
replicationcontrollers/nginx-controller

<span class="comment"># Check the replica</span>
$ kubectl get replicationControllers -l name=www-nginx         
<span class="caps">CONTROLLER</span>         CONTAINER(S)   IMAGE(S)   SELECTOR         REPLICAS
nginx-controller   nginx          nginx      name=www-nginx   2

<span class="comment"># Verify the connection to the pods</span>
$ kubectl get pods -l name=www-nginx                                                                                ✘130 
<span class="caps">POD</span>                      IP            CONTAINER(S)   IMAGE(S)   HOST                    LABELS           STATUS    CREATED      MESSAGE
nginx-controller-lfeo7   10.246.1.15                             10.245.1.3/10.245.1.3   name=www-nginx   Running   21 minutes   
                                       nginx          nginx                                               Running   21 minutes   
www                      10.246.1.11                             10.245.1.3/10.245.1.3   name=www-nginx   Running   28 minutes   
                                       nginx          nginx
</code></pre>
<p>You could easily verify that multiple nginx instances are&nbsp;running:</p>
<pre><code class="lang-bash">$ vagrant ssh minion-1
[vagrant@kubernetes-minion-1 ~]$ curl http://10.246.1.15
[vagrant@kubernetes-minion-1 ~]$ curl http://10.246.1.11
</code></pre>
<p>The different containers are not useful by itself. We would like to abstract all instances by a service. Create and load the service definition into&nbsp;kubernetes.</p>
<pre><code class="lang-yaml"><span class="comment"># 01-nginx-service.yaml</span>
<span class="attr">apiVersion:</span> <span class="string">v1beta3</span>
<span class="attr">kind:</span> <span class="string">Service</span>
<span class="attr">metadata:</span>
<span class="attr">  name:</span> <span class="string">nginx-endpoint</span>
<span class="attr">  labels:</span> 
<span class="attr">    name:</span> <span class="string">www-nginx</span>
<span class="attr">spec:</span>
<span class="attr">  ports:</span>
<span class="attr">    - port:</span> <span class="number">8000</span> <span class="comment"># the port that this service should serve on</span>
      <span class="comment"># the container on each pod to connect to, can be a name</span>
      <span class="comment"># (e.g. 'www') or a number (e.g. 80)</span>
<span class="attr">      targetPort:</span> <span class="number">80</span>
<span class="attr">      protocol:</span> <span class="string"><span class="caps">TCP</span></span>
  <span class="comment"># public ip of minion, only required for vagrant</span>
  <span class="comment"># just like the selector in the replication controller,</span>
  <span class="comment"># but this time it identifies the set of pods to load balance</span>
  <span class="comment"># traffic to.</span>
<span class="attr">  selector:</span>
<span class="attr">    name:</span> <span class="string">nginx</span>
</code></pre>
<pre><code class="lang-bash"><span class="comment"># Add public endpoint</span>
$ kubectl create -f 01-nginx-service.yaml
services/nginx-endpoint

<span class="comment"># Show all running endpoints</span>
$ kubectl get services -l name=www-nginx 
<span class="caps">NAME</span>             LABELS           SELECTOR     IP(S)           PORT(S)
nginx-endpoint   name=www-nginx   name=nginx   10.247.212.62   8000/TCP
</code></pre>
<p>Now we set up a <span class="caps">HTTP</span> Health Checks that will restart a the nginx container in case the application&nbsp;crashes.</p>
<pre><code class="lang-yaml"><span class="attr">apiVersion:</span> <span class="string">v1beta3</span>
<span class="attr">kind:</span> <span class="string">Pod</span>
<span class="attr">metadata:</span>
<span class="attr">  name:</span> <span class="string">nginx-healthcheck</span>
<span class="attr">  labels:</span> 
<span class="attr">    name:</span> <span class="string">www-nginx</span>
<span class="attr">spec:</span>
<span class="attr">  containers:</span>
<span class="attr">    - name:</span> <span class="string">nginx</span>
<span class="attr">      image:</span> <span class="string">nginx</span>
      <span class="comment"># defines the health checking</span>
<span class="attr">      livenessProbe:</span>
        <span class="comment"># an http probe</span>
<span class="attr">        httpGet:</span>
<span class="attr">          path:</span> <span class="string">/_status/healthz</span>
<span class="attr">          port:</span> <span class="number">80</span>
        <span class="comment"># length of time to wait for a pod to initialize</span>
        <span class="comment"># after pod startup, before applying health checking</span>
<span class="attr">        initialDelaySeconds:</span> <span class="number">30</span>
<span class="attr">        timeoutSeconds:</span> <span class="number">1</span>
<span class="attr">      ports:</span>
<span class="attr">        - containerPort:</span> <span class="number">80</span>
</code></pre>
<p>Add the health check to your&nbsp;cluster</p>
<pre><code class="lang-bash"><span class="comment"># add a health check</span>
kubectl create -f 01-nginx-health-check.yaml
</code></pre>
<p>Everything is setup properly. To destory the cluster, delete all definitions from&nbsp;kubernetes:</p>
<pre><code># Delete all added parts
$ kubectl delete -f 01-nginx-service.yaml 
$ kubectl delete -f 01-nginx.yaml
$ kubectl delete -f 01-nginx-health-check.yaml
</code></pre><p>Have fun with&nbsp;containers!</p>
<p>If you have any questions contact me via <a href="https://twitter.com/chri_hartmann">Twitter @chri_hartmann</a> or <a href="https://github.com/chris-rock">Github</a></p>
</section>
        </article>
      </div>
    </div>
    <footer>
      <div class="content-wrap">
        <div class="social center">
          <div class="network"><a href="javascript:window.location=%22http://news.ycombinator.com/submitlink?u=%22+encodeURIComponent(document.location)+%22&amp;amp;t=%22+encodeURIComponent(document.title)" class="hn-link">Discuss on Hacker News</a></div>
          <div class="network twitter"><a https://twitter.com/share data-via="chri_hartmann" data-count="none" class="twitter-share-button">Tweet</a></div>
        </div>
        <div class="nav"><a href="/">« Full blog</a></div>
        <section class="about">
        </section>
        <section class="copy">
          <p>&copy; 2017 Christoph Hartmann &mdash; powered by&nbsp;<a href="https://github.com/jnordberg/wintersmith">Wintersmith</a>
          </p>
        </section>
      </div>
    </footer>
  </body>
</html>